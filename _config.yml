intro:
title: 'Neural Additive Models: Interpretable Machine Learning with Neural Nets"
description:
- ICML 2020 Workshop on Human Interpretability in Machine Learning (Spotlight)
buttons:
  Paper: 'https://arxiv.org/pdf/2004.13912.pdf'
  Code: 'https://github.com/google-research/google-research/tree/master/neural_additive_models'
  TweetPrint: https://twitter.com/nickfrosst/status/1255889440083447810?s=20
  # Slides: 'pdfs/slides.pdf'
  # Poster: 'pdfs/neurips_drl_poster.pdf'
  # Talk: 'https://slideslive.com/38922701/contributed-talk-striving-for-simplicity-in-offpolicy-deep-reinforcement-learning' 
  Authors: '#authors'
